<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.8.26">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Parsa Idehpour">
<meta name="dcterms.date" content="2025-12-17">
<meta name="description" content="Intelligence didn’t evolve to solve puzzles—it evolved to control bodies. This reframes how we think about AI.">

<title>Why Bodies Matter: The Case for Embodied Intelligence – My Explorations with LLMs</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
</style>


<script src="../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../">
<script src="../../site_libs/quarto-html/quarto.js" type="module"></script>
<script src="../../site_libs/quarto-html/tabsets/tabsets.js" type="module"></script>
<script src="../../site_libs/quarto-html/axe/axe-check.js" type="module"></script>
<script src="../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting-587c61ba64f3a5504c4d52d930310e48.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../site_libs/bootstrap/bootstrap-0b37c64f34216b628666a8dac638b53b.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>


<link rel="stylesheet" href="../../styles.css">
</head>

<body class="nav-fixed fullcontent quarto-light">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top quarto-banner">
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a class="navbar-brand" href="../../index.html">
    <span class="navbar-title">My Explorations with LLMs</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" role="menu" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item">
    <a class="nav-link" href="../../about.html"> 
<span class="menu-text">About</span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://github.com/"> <i class="bi bi-github" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://twitter.com"> <i class="bi bi-twitter" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
</ul>
          </div> <!-- /navcollapse -->
            <div class="quarto-navbar-tools">
</div>
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<header id="title-block-header" class="quarto-title-block default page-columns page-full">
  <div class="quarto-title-banner page-columns page-full">
    <div class="quarto-title column-body">
      <h1 class="title">Why Bodies Matter: The Case for Embodied Intelligence</h1>
                  <div>
        <div class="description">
          Intelligence didn’t evolve to solve puzzles—it evolved to control bodies. This reframes how we think about AI.
        </div>
      </div>
                          <div class="quarto-categories">
                <div class="quarto-category">robotics</div>
                <div class="quarto-category">cognition</div>
                <div class="quarto-category">embodiment</div>
                <div class="quarto-category">philosophy</div>
              </div>
                  </div>
  </div>
    
  
  <div class="quarto-title-meta">

      <div>
      <div class="quarto-title-meta-heading">Author</div>
      <div class="quarto-title-meta-contents">
               <p>Parsa Idehpour </p>
            </div>
    </div>
      
      <div>
      <div class="quarto-title-meta-heading">Published</div>
      <div class="quarto-title-meta-contents">
        <p class="date">December 17, 2025</p>
      </div>
    </div>
    
      
    </div>
    
  
  </header><div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    
<!-- main -->
<main class="content quarto-banner-title-block" id="quarto-document-content">





<p>The dominant paradigm in AI treats intelligence as abstract computation: take in information, process it through learned functions, produce outputs. Bodies are incidental—useful for gathering data, maybe, but not constitutive of intelligence itself. This post argues that this framing misses something important, and that understanding why could reshape how we build and evaluate AI systems.</p>
<section id="the-sensorimotor-grounding-hypothesis" class="level2">
<h2 class="anchored" data-anchor-id="the-sensorimotor-grounding-hypothesis">The Sensorimotor Grounding Hypothesis</h2>
<p>The core claim of embodied cognition is that meaning is grounded in action. When you understand the word “grasp,” you don’t just retrieve a dictionary definition—you activate the same sensorimotor circuits involved in actually grasping. Concepts aren’t abstract symbols floating in a void; they’re patterns of potential interaction with the world.</p>
<p>This isn’t mysticism. It’s an empirical claim with testable predictions. If meaning is grounded in action, then:</p>
<ul>
<li>Processing action words should activate motor cortex (it does)</li>
<li>Interfering with motor systems should slow language comprehension (it does)</li>
<li>Abstract concepts should be structured through bodily metaphors (they are: we “grasp” ideas, “weigh” options, “move forward” with plans)</li>
</ul>
<p>The implications for AI are immediate. If human intelligence is fundamentally structured by embodiment, then systems trained only on text might develop a qualitatively different kind of “understanding”—one that correlates with human concepts but doesn’t share their grounding.</p>
</section>
<section id="moravecs-paradox-revisited" class="level2">
<h2 class="anchored" data-anchor-id="moravecs-paradox-revisited">Moravec’s Paradox Revisited</h2>
<p>In 1988, Hans Moravec observed something puzzling: tasks that seem hard for humans (chess, calculus) are easy for computers, while tasks that seem trivial (walking, recognizing objects, catching a ball) are extraordinarily difficult to automate.</p>
<p>The standard explanation is that evolution had billions of years to optimize sensorimotor control, while abstract reasoning is a recent and still-imperfect add-on. But there’s a deeper point: sensorimotor control is computationally harder than it looks because the real world is high-dimensional, noisy, and unforgiving.</p>
<p>Consider walking. You’re controlling ~600 muscles through a system with feedback delays of 50-200ms, balancing a top-heavy mass on two small contact points, while dealing with uneven terrain, unexpected obstacles, and perturbations. The state space is enormous. The dynamics are nonlinear. And failure (falling) has immediate, painful consequences.</p>
<p>Chess, by contrast, is turn-based, fully observable, discrete, deterministic, and consequence-free. The only reason it seemed hard to us is that our evolved hardware isn’t optimized for tree search. Once we build hardware that is, the problem evaporates.</p>
<p>Moravec’s paradox suggests that embodied intelligence isn’t just one variety of intelligence—it’s the hard case. Abstract reasoning might be a simplified special case that happens to be useful in certain domains.</p>
</section>
<section id="active-inference-and-predictive-processing" class="level2">
<h2 class="anchored" data-anchor-id="active-inference-and-predictive-processing">Active Inference and Predictive Processing</h2>
<p>One of the most compelling frameworks for embodied cognition comes from predictive processing. The idea: brains are fundamentally prediction machines. Perception isn’t passive reception of sensory data—it’s active inference, where the brain generates predictions and uses sensory input to correct them.</p>
<p>In this view, action and perception are two sides of the same coin:</p>
<ul>
<li><strong>Perception</strong> updates your model of the world to match sensory input</li>
<li><strong>Action</strong> changes the world to match your predictions</li>
</ul>
<p>Both serve the same goal: minimizing prediction error (or “free energy” in the technical literature).</p>
<p>This dissolves the traditional boundary between sensing and acting. An organism that just sits and models the world will accumulate prediction error. To minimize error, you must act—not just to gather information, but to bring the world into alignment with your expectations. “I predict I will be holding a coffee cup” becomes true when you pick one up.</p>
<p>Karl Friston’s formalization of this idea has become influential in neuroscience and is starting to influence robotics and AI. The core insight for our purposes: you can’t separate the “intelligence” part from the “body” part. The whole system is optimizing prediction, and action is essential to that optimization.</p>
</section>
<section id="brooks-and-intelligence-without-representation" class="level2">
<h2 class="anchored" data-anchor-id="brooks-and-intelligence-without-representation">Brooks and Intelligence Without Representation</h2>
<p>Rodney Brooks’ subsumption architecture from the 1980s was a direct attack on classical AI. Classical AI builds explicit representations of the world, reasons over them, and then acts. Brooks argued this was backwards: you should build layers of sensorimotor competence that directly couple perception to action, with higher layers modulating lower ones rather than replacing them.</p>
<p>His robots didn’t have world models in the traditional sense. They had reactive behaviors that, when combined, produced surprisingly competent navigation and exploration. “The world is its own best model,” Brooks argued—why build an expensive internal representation when you can query the real thing for free?</p>
<p>The subsumption architecture fell out of favor as machine learning enabled powerful learned representations. But Brooks’ core critique remains relevant:</p>
<ol type="1">
<li><strong>Representations are expensive</strong> in energy, time, and complexity</li>
<li><strong>The world provides information for free</strong> if you’re set up to exploit it</li>
<li><strong>Tight coupling between perception and action</strong> can produce robust behavior without elaborate reasoning</li>
</ol>
<p>Modern robotics has partially rediscovered these ideas through end-to-end learning, where policies map directly from sensors to actions without explicit intermediate representations. The representation is there, but it’s implicit and learned, not hand-designed.</p>
</section>
<section id="what-might-llms-be-missing" class="level2">
<h2 class="anchored" data-anchor-id="what-might-llms-be-missing">What Might LLMs Be Missing?</h2>
<p>If embodied cognition is right, what does that mean for language models trained only on text?</p>
<p>The strong claim would be: LLMs can never truly understand language because they lack sensorimotor grounding. They manipulate symbols that refer to concepts they’ve never experienced. This is essentially Searle’s Chinese Room argument updated for modern AI.</p>
<p>The weak claim: LLMs develop a different kind of understanding—one that captures statistical regularities in how words are used, which correlates strongly with grounded meaning but isn’t identical to it. This might explain certain systematic failures (spatial reasoning, physical intuition) while allowing for genuine competence in many domains.</p>
<p>There’s also a deflationary view: maybe grounding doesn’t matter as much as philosophers think. If statistical patterns in text capture enough of the structure of grounded concepts, then text-only training might be sufficient for most purposes. The correlation between “how words are used” and “what words mean” is so strong that you can get meaning for free by modeling usage.</p>
<p>I don’t think this debate is settled. But noticing it changes how you evaluate AI systems. “Does it produce correct outputs?” is different from “Does it understand in the way we do?” Both questions matter, depending on what you’re building.</p>
</section>
<section id="the-enactivist-extension" class="level2">
<h2 class="anchored" data-anchor-id="the-enactivist-extension">The Enactivist Extension</h2>
<p>Enactivism pushes embodied cognition further: cognition isn’t just grounded in the body—it’s constituted by the entire organism-environment system. Intelligence doesn’t reside “in the head”; it emerges from the dynamic coupling between brain, body, and world.</p>
<p>This sounds abstract, but it has concrete implications:</p>
<ul>
<li><strong>Offloading</strong>: Experts routinely offload cognitive work to external structures (notes, tools, social systems). The intelligence is in the coupled system, not just the brain.</li>
<li><strong>Stigmergy</strong>: Social insects coordinate through environmental modifications (pheromone trails). The “algorithm” is distributed across agents and environment.</li>
<li><strong>Affordances</strong>: Perception is already structured for action—we see a chair as “sittable,” a handle as “graspable.” The world shows up as opportunities for interaction, not raw sensory data.</li>
</ul>
<p>If enactivism is right, then building embodied AI isn’t just about putting a computer in a robot body. It’s about designing the entire system—agent, body, and environment—so that intelligence can emerge from their interaction.</p>
</section>
<section id="practical-implications" class="level2">
<h2 class="anchored" data-anchor-id="practical-implications">Practical Implications</h2>
<p>What does this mean for someone building AI systems?</p>
<ol type="1">
<li><p><strong>Don’t assume language is enough.</strong> Text captures a lot, but systematic gaps in physical reasoning might require different training data or architectures.</p></li>
<li><p><strong>Simulation has limits.</strong> If real-world interaction shapes cognition in deep ways, then sim-to-real gaps might be more fundamental than we assume.</p></li>
<li><p><strong>Multimodal training matters.</strong> Grounding language in vision, action, and interaction might not just add capabilities—it might change the nature of what’s learned.</p></li>
<li><p><strong>Evaluate for the right thing.</strong> If you need grounded understanding, test for it. If you need statistical text competence, test for that. They might come apart.</p></li>
<li><p><strong>Bodies aren’t optional for some applications.</strong> Household robots, surgical assistants, autonomous vehicles—these require genuine sensorimotor intelligence, not just language competence.</p></li>
</ol>
<p>The bigger point: intelligence is not a single thing. There are many kinds, optimized for different niches. Embodied intelligence is one important kind that we’re only beginning to understand how to build.</p>
<div style="text-align:center;">
  <img src="image.png" alt="Figure" width="65%">
  <p><em>Figure 1. Closed-loop sensorimotor integration vs. open-loop processing</em></p>
</div>


</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
  window.document.addEventListener("DOMContentLoaded", function (event) {
    const icon = "";
    const anchorJS = new window.AnchorJS();
    anchorJS.options = {
      placement: 'right',
      icon: icon
    };
    anchorJS.add('.anchored');
    const isCodeAnnotation = (el) => {
      for (const clz of el.classList) {
        if (clz.startsWith('code-annotation-')) {                     
          return true;
        }
      }
      return false;
    }
    const onCopySuccess = function(e) {
      // button target
      const button = e.trigger;
      // don't keep focus
      button.blur();
      // flash "checked"
      button.classList.add('code-copy-button-checked');
      var currentTitle = button.getAttribute("title");
      button.setAttribute("title", "Copied!");
      let tooltip;
      if (window.bootstrap) {
        button.setAttribute("data-bs-toggle", "tooltip");
        button.setAttribute("data-bs-placement", "left");
        button.setAttribute("data-bs-title", "Copied!");
        tooltip = new bootstrap.Tooltip(button, 
          { trigger: "manual", 
            customClass: "code-copy-button-tooltip",
            offset: [0, -8]});
        tooltip.show();    
      }
      setTimeout(function() {
        if (tooltip) {
          tooltip.hide();
          button.removeAttribute("data-bs-title");
          button.removeAttribute("data-bs-toggle");
          button.removeAttribute("data-bs-placement");
        }
        button.setAttribute("title", currentTitle);
        button.classList.remove('code-copy-button-checked');
      }, 1000);
      // clear code selection
      e.clearSelection();
    }
    const getTextToCopy = function(trigger) {
      const outerScaffold = trigger.parentElement.cloneNode(true);
      const codeEl = outerScaffold.querySelector('code');
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
    const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
      text: getTextToCopy
    });
    clipboard.on('success', onCopySuccess);
    if (window.document.getElementById('quarto-embedded-source-code-modal')) {
      const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
        text: getTextToCopy,
        container: window.document.getElementById('quarto-embedded-source-code-modal')
      });
      clipboardModal.on('success', onCopySuccess);
    }
      var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var mailtoRegex = new RegExp(/^mailto:/);
        var filterRegex = new RegExp("https:\/\/ParsaIdp\.github\.io\/comm4190_F25_Using_LLMs_Blog\/");
      var isInternal = (href) => {
          return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
      }
      // Inspect non-navigation links and adorn them if external
     var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
      for (var i=0; i<links.length; i++) {
        const link = links[i];
        if (!isInternal(link.href)) {
          // undo the damage that might have been done by quarto-nav.js in the case of
          // links that we want to consider external
          if (link.dataset.originalHref !== undefined) {
            link.href = link.dataset.originalHref;
          }
        }
      }
    function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
      const config = {
        allowHTML: true,
        maxWidth: 500,
        delay: 100,
        arrow: false,
        appendTo: function(el) {
            return el.parentElement;
        },
        interactive: true,
        interactiveBorder: 10,
        theme: 'quarto',
        placement: 'bottom-start',
      };
      if (contentFn) {
        config.content = contentFn;
      }
      if (onTriggerFn) {
        config.onTrigger = onTriggerFn;
      }
      if (onUntriggerFn) {
        config.onUntrigger = onUntriggerFn;
      }
      window.tippy(el, config); 
    }
    const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
    for (var i=0; i<noterefs.length; i++) {
      const ref = noterefs[i];
      tippyHover(ref, function() {
        // use id or data attribute instead here
        let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
        try { href = new URL(href).hash; } catch {}
        const id = href.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note) {
          return note.innerHTML;
        } else {
          return "";
        }
      });
    }
    const xrefs = window.document.querySelectorAll('a.quarto-xref');
    const processXRef = (id, note) => {
      // Strip column container classes
      const stripColumnClz = (el) => {
        el.classList.remove("page-full", "page-columns");
        if (el.children) {
          for (const child of el.children) {
            stripColumnClz(child);
          }
        }
      }
      stripColumnClz(note)
      if (id === null || id.startsWith('sec-')) {
        // Special case sections, only their first couple elements
        const container = document.createElement("div");
        if (note.children && note.children.length > 2) {
          container.appendChild(note.children[0].cloneNode(true));
          for (let i = 1; i < note.children.length; i++) {
            const child = note.children[i];
            if (child.tagName === "P" && child.innerText === "") {
              continue;
            } else {
              container.appendChild(child.cloneNode(true));
              break;
            }
          }
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(container);
          }
          return container.innerHTML
        } else {
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(note);
          }
          return note.innerHTML;
        }
      } else {
        // Remove any anchor links if they are present
        const anchorLink = note.querySelector('a.anchorjs-link');
        if (anchorLink) {
          anchorLink.remove();
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        if (note.classList.contains("callout")) {
          return note.outerHTML;
        } else {
          return note.innerHTML;
        }
      }
    }
    for (var i=0; i<xrefs.length; i++) {
      const xref = xrefs[i];
      tippyHover(xref, undefined, function(instance) {
        instance.disable();
        let url = xref.getAttribute('href');
        let hash = undefined; 
        if (url.startsWith('#')) {
          hash = url;
        } else {
          try { hash = new URL(url).hash; } catch {}
        }
        if (hash) {
          const id = hash.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note !== null) {
            try {
              const html = processXRef(id, note.cloneNode(true));
              instance.setContent(html);
            } finally {
              instance.enable();
              instance.show();
            }
          } else {
            // See if we can fetch this
            fetch(url.split('#')[0])
            .then(res => res.text())
            .then(html => {
              const parser = new DOMParser();
              const htmlDoc = parser.parseFromString(html, "text/html");
              const note = htmlDoc.getElementById(id);
              if (note !== null) {
                const html = processXRef(id, note);
                instance.setContent(html);
              } 
            }).finally(() => {
              instance.enable();
              instance.show();
            });
          }
        } else {
          // See if we can fetch a full url (with no hash to target)
          // This is a special case and we should probably do some content thinning / targeting
          fetch(url)
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.querySelector('main.content');
            if (note !== null) {
              // This should only happen for chapter cross references
              // (since there is no id in the URL)
              // remove the first header
              if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
                note.children[0].remove();
              }
              const html = processXRef(null, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      }, function(instance) {
      });
    }
        let selectedAnnoteEl;
        const selectorForAnnotation = ( cell, annotation) => {
          let cellAttr = 'data-code-cell="' + cell + '"';
          let lineAttr = 'data-code-annotation="' +  annotation + '"';
          const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
          return selector;
        }
        const selectCodeLines = (annoteEl) => {
          const doc = window.document;
          const targetCell = annoteEl.getAttribute("data-target-cell");
          const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
          const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
          const lines = annoteSpan.getAttribute("data-code-lines").split(",");
          const lineIds = lines.map((line) => {
            return targetCell + "-" + line;
          })
          let top = null;
          let height = null;
          let parent = null;
          if (lineIds.length > 0) {
              //compute the position of the single el (top and bottom and make a div)
              const el = window.document.getElementById(lineIds[0]);
              top = el.offsetTop;
              height = el.offsetHeight;
              parent = el.parentElement.parentElement;
            if (lineIds.length > 1) {
              const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
              const bottom = lastEl.offsetTop + lastEl.offsetHeight;
              height = bottom - top;
            }
            if (top !== null && height !== null && parent !== null) {
              // cook up a div (if necessary) and position it 
              let div = window.document.getElementById("code-annotation-line-highlight");
              if (div === null) {
                div = window.document.createElement("div");
                div.setAttribute("id", "code-annotation-line-highlight");
                div.style.position = 'absolute';
                parent.appendChild(div);
              }
              div.style.top = top - 2 + "px";
              div.style.height = height + 4 + "px";
              div.style.left = 0;
              let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
              if (gutterDiv === null) {
                gutterDiv = window.document.createElement("div");
                gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
                gutterDiv.style.position = 'absolute';
                const codeCell = window.document.getElementById(targetCell);
                const gutter = codeCell.querySelector('.code-annotation-gutter');
                gutter.appendChild(gutterDiv);
              }
              gutterDiv.style.top = top - 2 + "px";
              gutterDiv.style.height = height + 4 + "px";
            }
            selectedAnnoteEl = annoteEl;
          }
        };
        const unselectCodeLines = () => {
          const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
          elementsIds.forEach((elId) => {
            const div = window.document.getElementById(elId);
            if (div) {
              div.remove();
            }
          });
          selectedAnnoteEl = undefined;
        };
          // Handle positioning of the toggle
      window.addEventListener(
        "resize",
        throttle(() => {
          elRect = undefined;
          if (selectedAnnoteEl) {
            selectCodeLines(selectedAnnoteEl);
          }
        }, 10)
      );
      function throttle(fn, ms) {
      let throttle = false;
      let timer;
        return (...args) => {
          if(!throttle) { // first call gets through
              fn.apply(this, args);
              throttle = true;
          } else { // all the others get throttled
              if(timer) clearTimeout(timer); // cancel #2
              timer = setTimeout(() => {
                fn.apply(this, args);
                timer = throttle = false;
              }, ms);
          }
        };
      }
        // Attach click handler to the DT
        const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
        for (const annoteDlNode of annoteDls) {
          annoteDlNode.addEventListener('click', (event) => {
            const clickedEl = event.target;
            if (clickedEl !== selectedAnnoteEl) {
              unselectCodeLines();
              const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
              if (activeEl) {
                activeEl.classList.remove('code-annotation-active');
              }
              selectCodeLines(clickedEl);
              clickedEl.classList.add('code-annotation-active');
            } else {
              // Unselect the line
              unselectCodeLines();
              clickedEl.classList.remove('code-annotation-active');
            }
          });
        }
    const findCites = (el) => {
      const parentEl = el.parentElement;
      if (parentEl) {
        const cites = parentEl.dataset.cites;
        if (cites) {
          return {
            el,
            cites: cites.split(' ')
          };
        } else {
          return findCites(el.parentElement)
        }
      } else {
        return undefined;
      }
    };
    var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
    for (var i=0; i<bibliorefs.length; i++) {
      const ref = bibliorefs[i];
      const citeInfo = findCites(ref);
      if (citeInfo) {
        tippyHover(citeInfo.el, function() {
          var popup = window.document.createElement('div');
          citeInfo.cites.forEach(function(cite) {
            var citeDiv = window.document.createElement('div');
            citeDiv.classList.add('hanging-indent');
            citeDiv.classList.add('csl-entry');
            var biblioDiv = window.document.getElementById('ref-' + cite);
            if (biblioDiv) {
              citeDiv.innerHTML = biblioDiv.innerHTML;
            }
            popup.appendChild(citeDiv);
          });
          return popup.innerHTML;
        });
      }
    }
  });
  </script>
</div> <!-- /content -->




</body></html>