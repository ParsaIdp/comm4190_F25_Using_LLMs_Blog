{
  "cells": [
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "---\n",
        "title: \"Breakthrough #1 — Steering: How the First Brains Solved Navigation\"\n",
        "description: \"My AI-focused notes on Bennett’s ‘steering’ breakthrough: valence, action selection, and why bilateral bodies made brains worth it.\"\n",
        "author: \"Parsa Idehpour\"\n",
        "date: \"2025-12-16\"\n",
        "categories:\n",
        "  - neuroscience\n",
        "  - evolution\n",
        "  - reinforcement-learning\n",
        "  - control\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Bennett’s first “breakthrough” is intentionally humble. He isn’t trying to start the history of intelligence with something that resembles human thought. He starts with the first situation where having a nervous system pays for itself: once an organism can move, it must solve a control problem in real time.\n",
        "\n",
        "That control problem has a very specific flavor. The organism is bombarded by noisy sensory streams. The world is patchy: food is not everywhere, danger is not everywhere. The organism has limited energy and limited time. So it needs a way to pick the next motor command that tends, on average, to move it toward beneficial states and away from harmful ones. That’s steering.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "What’s easy to miss is that “steering” is already more than a reflex. Reflexes are local and brittle: they fire when a trigger appears, they don’t reconcile conflicts, and they don’t stabilize behavior over time. Steering, as Bennett uses the term, is the first place you see two properties that later become hallmarks of intelligence:\n",
        "\n",
        "1) **Integration.** Multiple cues compete. Odor says “go,” pain says “stop,” heat says “leave,” social signal says “approach.” Steering is the machinery that merges these into one coherent directional push.\n",
        "\n",
        "2) **Commitment.** If you change direction on every small fluctuation, you don’t get anywhere. Early nervous systems therefore need internal state—slow variables that persist and bias behavior for seconds to minutes. That’s how you get stable modes like exploration versus exploitation, approach versus avoidance, or “stay and forage” versus “get out now.”\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Bennett’s core claim is that the earliest brains build a tiny but powerful abstraction: **valence**. The world is carved into “good-for-me” and “bad-for-me” signals. That carving can be wired at the start (some stimuli are intrinsically appetitive or aversive), but it becomes conditional when internal state gets involved. The same cue can flip meaning depending on hunger, thirst, fatigue, or stress.\n",
        "\n",
        "This is the evolutionary origin of the objective function. Before you get learning, you get a stable notion of what counts as better versus worse. It sounds obvious, but it’s foundational: any agent-like system becomes interpretable only when you know what it’s trying to optimize. Bennett is saying: biology solved objective specification first, then built increasingly powerful machinery for optimizing it.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "A good way to see how strong steering can be is to picture an organism in a gradient (odor, temperature, salinity). If the signal gets better as it moves, keep going. If it gets worse, reorient. That kind of policy can look surprisingly purposeful because the environment itself is providing dense guidance. You don’t need a map if the world gives you “hotter/colder” feedback every second.\n",
        "\n",
        "There’s a deeper lesson here that generalizes beyond biology: a lot of competence comes from exploiting environmental structure, not from building elaborate internal representations. If the world offers smooth gradients, a small controller goes a long way. And if the world stops offering those gradients—if rewards become delayed, sparse, or deceptive—then the same controller hits a wall. Bennett’s whole staircase can be read as a sequence of upgrades that appear when the world becomes too hard for the previous controller class.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "From a math/ML viewpoint, I’d describe steering as a small, stable policy class coupled to a hard-coded reward prior. Early intelligence is not “general reasoning.” It’s the ability to turn sensory correlations into motion that improves survival. That’s why steering is such a good starting point: it forces you to take intelligence seriously as embodied control, not as disembodied problem-solving.\n",
        "\n",
        "If you want a pointed discussion question: what would count as the minimal internal state required to make steering robust? You can’t just say “approach good / avoid bad.” You need persistence, conflict resolution, and the ability to change what is “good” when the body’s needs change. That’s already the seed of later reinforcement learning.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "\n",
        "```{=html}\n",
        "<div style=\"text-align:center;\">\n",
        "  <img src=\"image.png\" alt=\"Gradient following\" width=\"65%\"/>\n",
        "  <p><em>Figure 1. Gradient-following behavior as a minimal navigation strategy</em></p>\n",
        "</div>\n",
        "```\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
