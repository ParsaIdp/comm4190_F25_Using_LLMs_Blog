<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.8.26">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Parsa Idehpour">
<meta name="dcterms.date" content="2025-12-17">
<meta name="description" content="Model quality isn’t fixed at training time. With search, verification, and refinement, inference compute can substitute for parameters.">

<title>Thinking Longer: Test-Time Compute and the Future of Inference Scaling – My Explorations with LLMs</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
</style>


<script src="../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../">
<script src="../../site_libs/quarto-html/quarto.js" type="module"></script>
<script src="../../site_libs/quarto-html/tabsets/tabsets.js" type="module"></script>
<script src="../../site_libs/quarto-html/axe/axe-check.js" type="module"></script>
<script src="../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting-587c61ba64f3a5504c4d52d930310e48.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../site_libs/bootstrap/bootstrap-0b37c64f34216b628666a8dac638b53b.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>


<link rel="stylesheet" href="../../styles.css">
</head>

<body class="nav-fixed fullcontent quarto-light">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top quarto-banner">
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a class="navbar-brand" href="../../index.html">
    <span class="navbar-title">My Explorations with LLMs</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" role="menu" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item">
    <a class="nav-link" href="../../about.html"> 
<span class="menu-text">About</span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://github.com/"> <i class="bi bi-github" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://twitter.com"> <i class="bi bi-twitter" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
</ul>
          </div> <!-- /navcollapse -->
            <div class="quarto-navbar-tools">
</div>
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<header id="title-block-header" class="quarto-title-block default page-columns page-full">
  <div class="quarto-title-banner page-columns page-full">
    <div class="quarto-title column-body">
      <h1 class="title">Thinking Longer: Test-Time Compute and the Future of Inference Scaling</h1>
                  <div>
        <div class="description">
          Model quality isn’t fixed at training time. With search, verification, and refinement, inference compute can substitute for parameters.
        </div>
      </div>
                          <div class="quarto-categories">
                <div class="quarto-category">LLMs</div>
                <div class="quarto-category">inference</div>
                <div class="quarto-category">reasoning</div>
                <div class="quarto-category">scaling</div>
              </div>
                  </div>
  </div>
    
  
  <div class="quarto-title-meta">

      <div>
      <div class="quarto-title-meta-heading">Author</div>
      <div class="quarto-title-meta-contents">
               <p>Parsa Idehpour </p>
            </div>
    </div>
      
      <div>
      <div class="quarto-title-meta-heading">Published</div>
      <div class="quarto-title-meta-contents">
        <p class="date">December 17, 2025</p>
      </div>
    </div>
    
      
    </div>
    
  
  </header><div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    
<!-- main -->
<main class="content quarto-banner-title-block" id="quarto-document-content">





<p>The dominant paradigm for improving language models has been scaling training: more parameters, more data, more compute. But there’s another dimension: <strong>test-time compute</strong>—spending more resources at inference time to get better answers.</p>
<p>Humans do this naturally. Hard problems require more thought. You don’t solve a complex proof in one mental step; you work through intermediate results, backtrack when stuck, and verify your reasoning. What happens when we teach AI systems to do the same?</p>
<section id="the-test-time-compute-hypothesis" class="level2">
<h2 class="anchored" data-anchor-id="the-test-time-compute-hypothesis">The Test-Time Compute Hypothesis</h2>
<p>The core idea: a small model that “thinks” for 10 seconds might outperform a large model that answers in 100 milliseconds. If you’re willing to spend compute at inference time, you can trade it for training-time compute.</p>
<p>This isn’t free. Inference compute costs money and time. But for many applications—complex reasoning, code generation, mathematical proofs—accuracy matters more than latency. And inference compute is more flexible: you can allocate it dynamically based on problem difficulty.</p>
<p>The question is how to spend that compute productively. Simply generating more tokens doesn’t help if those tokens are noise. You need structured ways to explore, evaluate, and refine.</p>
</section>
<section id="chain-of-thought-prompting" class="level2">
<h2 class="anchored" data-anchor-id="chain-of-thought-prompting">Chain-of-Thought Prompting</h2>
<p>The simplest form of test-time compute: ask the model to show its work.</p>
<p><strong>Chain-of-thought (CoT)</strong> prompting includes examples with step-by-step reasoning, then asks the model to produce similar intermediate steps. This dramatically improves performance on math, logic, and multi-step reasoning problems.</p>
<p>Why does it work? Several hypotheses:</p>
<ul>
<li><strong>Serialized computation</strong>: Transformers have limited depth. Generating intermediate tokens effectively adds more “layers” of computation.</li>
<li><strong>Error decomposition</strong>: Breaking problems into steps exposes intermediate results that are easier to verify and correct.</li>
<li><strong>Training distribution</strong>: Models are trained on text that includes reasoning. Prompting them to reason recovers abilities learned during training.</li>
</ul>
<p><strong>Zero-shot CoT</strong>: Just adding “Let’s think step by step” to the prompt induces reasoning without examples. This suggests CoT is unlocking something the model already knows how to do.</p>
<p>Limitation: CoT is a single forward pass. The model generates one chain and commits to it. It can’t explore alternatives or backtrack.</p>
</section>
<section id="best-of-n-and-self-consistency" class="level2">
<h2 class="anchored" data-anchor-id="best-of-n-and-self-consistency">Best-of-N and Self-Consistency</h2>
<p>Generate multiple answers; pick the best one.</p>
<p><strong>Best-of-N sampling</strong>: Generate N independent completions, score them somehow (model confidence, ground truth if available, external verifier), and return the best. Simple but effective. Often 4-8 samples provide most of the gain.</p>
<p><strong>Self-consistency</strong>: For problems with a single correct answer (math, factual questions), generate N reasoning chains and take the majority vote on the final answer. Different reasoning paths might make different intermediate errors but converge on the correct final answer.</p>
<p>These methods use test-time compute to reduce variance—sampling multiple times and aggregating. They work because model stochasticity produces diverse solutions, some of which are better than others.</p>
<p>Limitation: Linear cost in N. Each sample requires a full forward pass. And if all N chains converge to the same wrong answer, more sampling doesn’t help.</p>
</section>
<section id="tree-search-for-language" class="level2">
<h2 class="anchored" data-anchor-id="tree-search-for-language">Tree Search for Language</h2>
<p>Instead of generating complete sequences and scoring afterward, build a tree of partial sequences and search.</p>
<p><strong>Monte Carlo Tree Search (MCTS)</strong>: The approach that powered AlphaGo. Treat sequence generation as a game tree. At each position, expand promising branches, simulate to completion, and backpropagate value estimates. Balance exploration (trying new branches) and exploitation (deepening good ones).</p>
<p>Applied to language: 1. Start with prompt 2. Generate several possible continuations (tokens or phrases) 3. Score each branch with a value estimate 4. Expand the most promising branches 5. Continue until a complete answer, then backpropagate</p>
<p>This enables backtracking: if a reasoning path leads to a dead end, you can return to an earlier branch and try differently.</p>
<p><strong>Process Reward Models (PRMs)</strong>: Train a model to score intermediate reasoning steps, not just final answers. A PRM can identify when reasoning goes wrong before reaching the conclusion, enabling earlier pruning.</p>
<p><strong>Outcome Reward Models (ORMs)</strong>: Score only final answers. Simpler to train (you just need answer labels) but less useful for guiding search.</p>
<p>Tree search with PRMs is how recent “reasoning models” achieve their performance. The model doesn’t just generate one chain; it explores a tree of possibilities, guided by learned value estimates.</p>
</section>
<section id="self-critique-and-iterative-refinement" class="level2">
<h2 class="anchored" data-anchor-id="self-critique-and-iterative-refinement">Self-Critique and Iterative Refinement</h2>
<p>Generate once, then improve.</p>
<p><strong>Self-critique</strong>: Ask the model to evaluate its own answer. “What might be wrong with this solution?” “Are there any errors in this proof?” The model often identifies issues it failed to avoid during generation.</p>
<p><strong>Iterative refinement</strong>: Generate → critique → revise → repeat. Each pass can fix errors from the previous one. Analogous to how humans edit their writing.</p>
<p><strong>Constitutional AI-style loops</strong>: Define principles (“be helpful, harmless, honest”), generate candidate responses, rank them by the principles, and train on the rankings. The same idea applies at inference: generate, critique against principles, and revise.</p>
<p>Why can models catch errors on review that they made during generation? Partly because generation is autoregressive and committing—once tokens are emitted, they influence subsequent generation. Review operates on a complete artifact and can consider global coherence.</p>
</section>
<section id="verifier-guided-generation" class="level2">
<h2 class="anchored" data-anchor-id="verifier-guided-generation">Verifier-Guided Generation</h2>
<p>Use a separate model to verify outputs, and let that verification guide generation.</p>
<p><strong>Code</strong>: Generate code → run tests → if tests fail, generate again with error context. The test suite is an external verifier. This is how many code-completion systems work in practice.</p>
<p><strong>Math</strong>: Generate proof steps → check with a formal verifier (Lean, Coq) → if verification fails, backtrack. The theorem prover provides ground truth.</p>
<p><strong>Factual claims</strong>: Generate → retrieve sources → verify claims against sources → revise. Retrieval-augmented generation as verification.</p>
<p>External verifiers are powerful because they provide reliable signal. If your code doesn’t compile, that’s ground truth—no model uncertainty involved. The challenge is that not all tasks have clean external verification.</p>
</section>
<section id="compute-optimal-inference" class="level2">
<h2 class="anchored" data-anchor-id="compute-optimal-inference">Compute-Optimal Inference</h2>
<p>When should you think more? Not every query deserves the same effort.</p>
<p><strong>Adaptive compute</strong>: Estimate problem difficulty and allocate inference compute accordingly. Simple questions get one-shot answers; hard questions get tree search and verification.</p>
<p>Difficulty estimation is its own challenge: - Model confidence (entropy over tokens) is one signal but unreliable - Query characteristics (length, complexity, domain) provide hints - Start with cheap computation; escalate if initial results seem uncertain</p>
<p><strong>Cascading</strong>: Try a small, fast model first. If confidence is low, hand off to a larger model. Most queries might be handled cheaply; only hard cases pay the full cost.</p>
<p><strong>Speculative decoding</strong>: Use a small model to draft continuations; verify with the large model. If verification passes, you’ve generated many tokens cheaply. If not, fall back to the large model. This accelerates easy continuations while maintaining large-model quality.</p>
</section>
<section id="openais-o-series-and-the-reasoning-model-paradigm" class="level2">
<h2 class="anchored" data-anchor-id="openais-o-series-and-the-reasoning-model-paradigm">OpenAI’s “o-series” and the Reasoning Model Paradigm</h2>
<p>OpenAI’s o1 (and predecessors like “Strawberry”) represent this paradigm taken seriously. Key characteristics:</p>
<ul>
<li><strong>Extended reasoning</strong>: The model generates substantial internal reasoning before answering. This might be hidden from users but consumes inference compute.</li>
<li><strong>Process supervision</strong>: Trained with reward on intermediate reasoning steps, not just final answers.</li>
<li><strong>Search</strong>: Likely uses some form of tree search or best-of-N at inference time.</li>
<li><strong>Specialized for reasoning</strong>: Optimized for math, code, and logic where verification is possible.</li>
</ul>
<p>The result: dramatically better performance on hard reasoning benchmarks (AIME math, competition programming) at the cost of higher latency and expense.</p>
<p>This points toward a future where you might choose between: - Fast, cheap models for simple queries - Slow, expensive reasoning models for hard problems</p>
<p>Compute becomes a knob you turn based on problem difficulty and quality requirements.</p>
</section>
<section id="implications-and-trade-offs" class="level2">
<h2 class="anchored" data-anchor-id="implications-and-trade-offs">Implications and Trade-offs</h2>
<p><strong>Latency vs.&nbsp;quality</strong>: More thinking means slower responses. Acceptable for some applications (research, coding, analysis) but not others (chat, real-time decisions).</p>
<p><strong>Cost</strong>: Inference compute isn’t free. Tree search with process reward models can cost 10-100× single-pass inference. This changes the economics of AI applications.</p>
<p><strong>Training incentives</strong>: If models are deployed with test-time search, training should optimize for search performance, not just single-pass accuracy. This is an active research area.</p>
<p><strong>Transparency</strong>: Hidden reasoning (as in some o1 deployments) trades interpretability for performance. Users may not understand why answers take time or why they cost more.</p>
<p><strong>Diminishing returns</strong>: At some point, no amount of inference compute helps. If the model doesn’t have the right knowledge or capability, thinking longer doesn’t create it.</p>
</section>
<section id="the-bigger-picture" class="level2">
<h2 class="anchored" data-anchor-id="the-bigger-picture">The Bigger Picture</h2>
<p>Test-time compute represents a shift in how we think about AI capability. Instead of a fixed model with fixed abilities, we have a continuum: spend more compute, get better answers.</p>
<p>This is closer to how intelligence works in nature. Humans don’t have one-shot answers to hard problems. We think, revise, verify, and iterate. The question is whether current architectures—transformers with autoregressive generation—can fully exploit this paradigm, or whether deeper architectural changes are needed.</p>
<p>Either way, the message is clear: model quality at deployment isn’t determined only by training. How you use the model matters too.</p>
<div style="text-align:center;">
  <img src="image.png" alt="Figure" width="65%">
  <p><em>Figure 1. Trading off training compute vs. inference compute</em></p>
</div>


</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
  window.document.addEventListener("DOMContentLoaded", function (event) {
    const icon = "";
    const anchorJS = new window.AnchorJS();
    anchorJS.options = {
      placement: 'right',
      icon: icon
    };
    anchorJS.add('.anchored');
    const isCodeAnnotation = (el) => {
      for (const clz of el.classList) {
        if (clz.startsWith('code-annotation-')) {                     
          return true;
        }
      }
      return false;
    }
    const onCopySuccess = function(e) {
      // button target
      const button = e.trigger;
      // don't keep focus
      button.blur();
      // flash "checked"
      button.classList.add('code-copy-button-checked');
      var currentTitle = button.getAttribute("title");
      button.setAttribute("title", "Copied!");
      let tooltip;
      if (window.bootstrap) {
        button.setAttribute("data-bs-toggle", "tooltip");
        button.setAttribute("data-bs-placement", "left");
        button.setAttribute("data-bs-title", "Copied!");
        tooltip = new bootstrap.Tooltip(button, 
          { trigger: "manual", 
            customClass: "code-copy-button-tooltip",
            offset: [0, -8]});
        tooltip.show();    
      }
      setTimeout(function() {
        if (tooltip) {
          tooltip.hide();
          button.removeAttribute("data-bs-title");
          button.removeAttribute("data-bs-toggle");
          button.removeAttribute("data-bs-placement");
        }
        button.setAttribute("title", currentTitle);
        button.classList.remove('code-copy-button-checked');
      }, 1000);
      // clear code selection
      e.clearSelection();
    }
    const getTextToCopy = function(trigger) {
      const outerScaffold = trigger.parentElement.cloneNode(true);
      const codeEl = outerScaffold.querySelector('code');
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
    const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
      text: getTextToCopy
    });
    clipboard.on('success', onCopySuccess);
    if (window.document.getElementById('quarto-embedded-source-code-modal')) {
      const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
        text: getTextToCopy,
        container: window.document.getElementById('quarto-embedded-source-code-modal')
      });
      clipboardModal.on('success', onCopySuccess);
    }
      var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var mailtoRegex = new RegExp(/^mailto:/);
        var filterRegex = new RegExp("https:\/\/ParsaIdp\.github\.io\/comm4190_F25_Using_LLMs_Blog\/");
      var isInternal = (href) => {
          return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
      }
      // Inspect non-navigation links and adorn them if external
     var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
      for (var i=0; i<links.length; i++) {
        const link = links[i];
        if (!isInternal(link.href)) {
          // undo the damage that might have been done by quarto-nav.js in the case of
          // links that we want to consider external
          if (link.dataset.originalHref !== undefined) {
            link.href = link.dataset.originalHref;
          }
        }
      }
    function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
      const config = {
        allowHTML: true,
        maxWidth: 500,
        delay: 100,
        arrow: false,
        appendTo: function(el) {
            return el.parentElement;
        },
        interactive: true,
        interactiveBorder: 10,
        theme: 'quarto',
        placement: 'bottom-start',
      };
      if (contentFn) {
        config.content = contentFn;
      }
      if (onTriggerFn) {
        config.onTrigger = onTriggerFn;
      }
      if (onUntriggerFn) {
        config.onUntrigger = onUntriggerFn;
      }
      window.tippy(el, config); 
    }
    const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
    for (var i=0; i<noterefs.length; i++) {
      const ref = noterefs[i];
      tippyHover(ref, function() {
        // use id or data attribute instead here
        let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
        try { href = new URL(href).hash; } catch {}
        const id = href.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note) {
          return note.innerHTML;
        } else {
          return "";
        }
      });
    }
    const xrefs = window.document.querySelectorAll('a.quarto-xref');
    const processXRef = (id, note) => {
      // Strip column container classes
      const stripColumnClz = (el) => {
        el.classList.remove("page-full", "page-columns");
        if (el.children) {
          for (const child of el.children) {
            stripColumnClz(child);
          }
        }
      }
      stripColumnClz(note)
      if (id === null || id.startsWith('sec-')) {
        // Special case sections, only their first couple elements
        const container = document.createElement("div");
        if (note.children && note.children.length > 2) {
          container.appendChild(note.children[0].cloneNode(true));
          for (let i = 1; i < note.children.length; i++) {
            const child = note.children[i];
            if (child.tagName === "P" && child.innerText === "") {
              continue;
            } else {
              container.appendChild(child.cloneNode(true));
              break;
            }
          }
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(container);
          }
          return container.innerHTML
        } else {
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(note);
          }
          return note.innerHTML;
        }
      } else {
        // Remove any anchor links if they are present
        const anchorLink = note.querySelector('a.anchorjs-link');
        if (anchorLink) {
          anchorLink.remove();
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        if (note.classList.contains("callout")) {
          return note.outerHTML;
        } else {
          return note.innerHTML;
        }
      }
    }
    for (var i=0; i<xrefs.length; i++) {
      const xref = xrefs[i];
      tippyHover(xref, undefined, function(instance) {
        instance.disable();
        let url = xref.getAttribute('href');
        let hash = undefined; 
        if (url.startsWith('#')) {
          hash = url;
        } else {
          try { hash = new URL(url).hash; } catch {}
        }
        if (hash) {
          const id = hash.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note !== null) {
            try {
              const html = processXRef(id, note.cloneNode(true));
              instance.setContent(html);
            } finally {
              instance.enable();
              instance.show();
            }
          } else {
            // See if we can fetch this
            fetch(url.split('#')[0])
            .then(res => res.text())
            .then(html => {
              const parser = new DOMParser();
              const htmlDoc = parser.parseFromString(html, "text/html");
              const note = htmlDoc.getElementById(id);
              if (note !== null) {
                const html = processXRef(id, note);
                instance.setContent(html);
              } 
            }).finally(() => {
              instance.enable();
              instance.show();
            });
          }
        } else {
          // See if we can fetch a full url (with no hash to target)
          // This is a special case and we should probably do some content thinning / targeting
          fetch(url)
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.querySelector('main.content');
            if (note !== null) {
              // This should only happen for chapter cross references
              // (since there is no id in the URL)
              // remove the first header
              if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
                note.children[0].remove();
              }
              const html = processXRef(null, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      }, function(instance) {
      });
    }
        let selectedAnnoteEl;
        const selectorForAnnotation = ( cell, annotation) => {
          let cellAttr = 'data-code-cell="' + cell + '"';
          let lineAttr = 'data-code-annotation="' +  annotation + '"';
          const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
          return selector;
        }
        const selectCodeLines = (annoteEl) => {
          const doc = window.document;
          const targetCell = annoteEl.getAttribute("data-target-cell");
          const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
          const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
          const lines = annoteSpan.getAttribute("data-code-lines").split(",");
          const lineIds = lines.map((line) => {
            return targetCell + "-" + line;
          })
          let top = null;
          let height = null;
          let parent = null;
          if (lineIds.length > 0) {
              //compute the position of the single el (top and bottom and make a div)
              const el = window.document.getElementById(lineIds[0]);
              top = el.offsetTop;
              height = el.offsetHeight;
              parent = el.parentElement.parentElement;
            if (lineIds.length > 1) {
              const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
              const bottom = lastEl.offsetTop + lastEl.offsetHeight;
              height = bottom - top;
            }
            if (top !== null && height !== null && parent !== null) {
              // cook up a div (if necessary) and position it 
              let div = window.document.getElementById("code-annotation-line-highlight");
              if (div === null) {
                div = window.document.createElement("div");
                div.setAttribute("id", "code-annotation-line-highlight");
                div.style.position = 'absolute';
                parent.appendChild(div);
              }
              div.style.top = top - 2 + "px";
              div.style.height = height + 4 + "px";
              div.style.left = 0;
              let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
              if (gutterDiv === null) {
                gutterDiv = window.document.createElement("div");
                gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
                gutterDiv.style.position = 'absolute';
                const codeCell = window.document.getElementById(targetCell);
                const gutter = codeCell.querySelector('.code-annotation-gutter');
                gutter.appendChild(gutterDiv);
              }
              gutterDiv.style.top = top - 2 + "px";
              gutterDiv.style.height = height + 4 + "px";
            }
            selectedAnnoteEl = annoteEl;
          }
        };
        const unselectCodeLines = () => {
          const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
          elementsIds.forEach((elId) => {
            const div = window.document.getElementById(elId);
            if (div) {
              div.remove();
            }
          });
          selectedAnnoteEl = undefined;
        };
          // Handle positioning of the toggle
      window.addEventListener(
        "resize",
        throttle(() => {
          elRect = undefined;
          if (selectedAnnoteEl) {
            selectCodeLines(selectedAnnoteEl);
          }
        }, 10)
      );
      function throttle(fn, ms) {
      let throttle = false;
      let timer;
        return (...args) => {
          if(!throttle) { // first call gets through
              fn.apply(this, args);
              throttle = true;
          } else { // all the others get throttled
              if(timer) clearTimeout(timer); // cancel #2
              timer = setTimeout(() => {
                fn.apply(this, args);
                timer = throttle = false;
              }, ms);
          }
        };
      }
        // Attach click handler to the DT
        const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
        for (const annoteDlNode of annoteDls) {
          annoteDlNode.addEventListener('click', (event) => {
            const clickedEl = event.target;
            if (clickedEl !== selectedAnnoteEl) {
              unselectCodeLines();
              const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
              if (activeEl) {
                activeEl.classList.remove('code-annotation-active');
              }
              selectCodeLines(clickedEl);
              clickedEl.classList.add('code-annotation-active');
            } else {
              // Unselect the line
              unselectCodeLines();
              clickedEl.classList.remove('code-annotation-active');
            }
          });
        }
    const findCites = (el) => {
      const parentEl = el.parentElement;
      if (parentEl) {
        const cites = parentEl.dataset.cites;
        if (cites) {
          return {
            el,
            cites: cites.split(' ')
          };
        } else {
          return findCites(el.parentElement)
        }
      } else {
        return undefined;
      }
    };
    var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
    for (var i=0; i<bibliorefs.length; i++) {
      const ref = bibliorefs[i];
      const citeInfo = findCites(ref);
      if (citeInfo) {
        tippyHover(citeInfo.el, function() {
          var popup = window.document.createElement('div');
          citeInfo.cites.forEach(function(cite) {
            var citeDiv = window.document.createElement('div');
            citeDiv.classList.add('hanging-indent');
            citeDiv.classList.add('csl-entry');
            var biblioDiv = window.document.getElementById('ref-' + cite);
            if (biblioDiv) {
              citeDiv.innerHTML = biblioDiv.innerHTML;
            }
            popup.appendChild(citeDiv);
          });
          return popup.innerHTML;
        });
      }
    }
  });
  </script>
</div> <!-- /content -->




</body></html>